{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Importing Libraries"
      ],
      "metadata": {
        "id": "6Ldj2BT-OPP5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import time\n",
        "from collections import Counter\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler,MinMaxScaler,LabelEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import KFold, StratifiedKFold, RepeatedStratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix, f1_score\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "eh_JKAjxOLmr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Loading Data"
      ],
      "metadata": {
        "id": "dohcFP-mN8Xl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# data_to_load = files.upload()"
      ],
      "metadata": {
        "id": "o4Vk9Mx7N-nF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "#df = pd.read_csv(io.BytesIO(data_to_load['RTA Dataset.csv']))\n",
        "df=pd.read_csv(r\"/content/RTA Dataset.csv\")"
      ],
      "metadata": {
        "id": "-dYoVJJGOE1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "wY-lA-0YOgJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail()"
      ],
      "metadata": {
        "id": "xDMBC2nYOiA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.sample(5)"
      ],
      "metadata": {
        "id": "hz8RSSUhOjK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Exploratory Data Analysis"
      ],
      "metadata": {
        "id": "0MWf-Eh9PI5C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1. EDA - Basic"
      ],
      "metadata": {
        "id": "caT4OfKkPNa0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "g-ZWX_v2PRKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "ip_l6F20SOlG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "G99dhuIzPbTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "id": "7x8MeB0SPeOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().all().sum() # No features are with all missing values"
      ],
      "metadata": {
        "id": "I6Hh0HrXPy-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().any().sum() # 16 Features with some missing values"
      ],
      "metadata": {
        "id": "Qfs_YoBYPiDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missing_value_df = pd.DataFrame({'Missing Counts' : df.isnull().sum(), 'percent_missing': round(df.isnull().sum() * 100 / len(df), 2)})\n",
        "missing_value_df.sort_values('percent_missing', ascending = False , inplace=True)\n",
        "\n",
        "missing_value_df #What are those features with some missing values and their proportion to the total."
      ],
      "metadata": {
        "id": "xpQDidXxRYbh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.duplicated().sum() #No duplicates"
      ],
      "metadata": {
        "id": "i6-6u8IWStEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe().T"
      ],
      "metadata": {
        "id": "fqA35t0pS2zf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe(include=\"object\").T"
      ],
      "metadata": {
        "id": "SWdErMr-TvXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Insights : \n",
        "\n",
        "# Most accidents are of severity : \"Slight Injury\" and happened due vehicles collision.\n",
        "# Root Cause Of the Collision : No Distancing between vehicles.\n",
        "# Driver Stats : Male, Age Band [18-30], Junior High School, Employee, 5-10 Yrs Exp.\n",
        "# Vehicle Stats : Automobile, Private Vehicle, No Defect, Service Year - Unknown.\n",
        "# Time Stats : Friday Evening [3:30 PM], Daylight , Normal Weather\n",
        "# Place Stats : Other, Two-way lanes (divided with broken lines road marking), Y Shape Junction\n",
        "# Road Stats : Tangent road with flat terrain, Asphalt roads, Dry"
      ],
      "metadata": {
        "id": "KoO_sN92T_KU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2. EDA - Advanced"
      ],
      "metadata": {
        "id": "DBIY3UksUHmX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.2.1. EDA - Advanced - Numerical features analysis"
      ],
      "metadata": {
        "id": "PZvfbF3VgRtO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.hist(layout=(1,2), figsize=(6,3))\n",
        "plt.show()\n",
        "\n",
        "#Insight : Majority of accidents are by 1 or 2 vehicles and casualties are <=3."
      ],
      "metadata": {
        "id": "U6EEUaVefhAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(data=df, y='Number_of_vehicles_involved')\n",
        "plt.show()\n",
        "\n",
        "# Insights : Majorly, 2 vehicles. Outliers are present."
      ],
      "metadata": {
        "id": "20JNNEgwg1JO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(data=df, y='Number_of_casualties')\n",
        "plt.show()\n",
        "\n",
        "# Insights : 50% of data with, 2 casualties. Outliers are present."
      ],
      "metadata": {
        "id": "S36qn0lqg377"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.pairplot(data = df)\n",
        "plt.show() #No Correlation between Number_of_vehicles_involved & Number_of_Casualties."
      ],
      "metadata": {
        "id": "nhkFQUd0UKWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.pairplot(data = df, vars = ['Number_of_vehicles_involved', 'Number_of_casualties'], hue = 'Accident_severity', markers=[\"o\", \"s\", \"D\"], height = 3, kind = 'reg')\n",
        "plt.show() \n",
        "\n",
        "#No Correlation between Number_of_vehicles_involved & Number_of_Casualties. [May be there is a pattern in Fatal Injury, Less No.of.vehicles involved, fatal inuries]"
      ],
      "metadata": {
        "id": "tvtUGltNVXco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(df[['Number_of_vehicles_involved','Number_of_casualties']].corr(), annot=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xtwnGbcJZptq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "sns.set_style('dark')\n",
        "sns.histplot(data = df, x= 'Number_of_vehicles_involved', hue = 'Accident_severity', binwidth=1, multiple=\"stack\") #or use 'bins'\n",
        "plt.show()\n",
        "\n",
        "# Insights : More Fatal Injuries when No. of Vehicles Involved = 2 [May be due vehicle-vehicle collision]"
      ],
      "metadata": {
        "id": "YXrIw9ABaRsA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "sns.set_style('dark')\n",
        "sns.histplot(data = df, x= 'Number_of_casualties', hue = 'Accident_severity', binwidth=1, multiple=\"stack\") #or use 'bins'\n",
        "plt.show()\n",
        "\n",
        "# Insights : Majorly ONE Person has injured, with Fatal Injury. [May be the Rider]"
      ],
      "metadata": {
        "id": "PQ5Z21u3amPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "sns.set_style('dark')\n",
        "sns.histplot(data = df, x= 'Number_of_vehicles_involved', hue = 'Number_of_casualties', binwidth=1, multiple=\"stack\") #or use 'bins'\n",
        "plt.show()\n",
        "\n",
        "# Insights : More Casualities, when no of vehicles involved <= 3, Majorly when 2. [Vehicles Collision?]"
      ],
      "metadata": {
        "id": "ZYyJV5uvfafX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.2.2 EDA - Advanced - Categorical Features Analysis"
      ],
      "metadata": {
        "id": "l_MvnBRAgbaW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,7))\n",
        "plt.pie(x=df['Accident_severity'].value_counts().values,\n",
        "        labels=df['Accident_severity'].value_counts().index,\n",
        "        autopct='%2.2f%%')\n",
        "plt.show() # 80% of Accidents ended up with Slight Injury."
      ],
      "metadata": {
        "id": "pUlbkGjbha0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Time']= pd.to_datetime(df['Time'])\n",
        "\n",
        "df['Hour']= df['Time'].dt.hour\n",
        "df['Minute']= df['Time'].dt.minute\n"
      ],
      "metadata": {
        "id": "eCDm2HZQklJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(['Time'], axis=1, inplace = True)"
      ],
      "metadata": {
        "id": "K7zkouTA0hxf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for column in df.select_dtypes(include=['object']).columns[:-1] :\n",
        "#   sns.countplot(data=df, y= column) #linewidth=2, edgecolor=sns.color_palette(\"dark\", 3)) #palette=\"rainbow\"\n",
        "#   plt.xticks(rotation=45, horizontalalignment='right', fontweight='light')\n",
        "#   plt.show() Note : DF.describe explained the same\n",
        "\n",
        "for column in ['Hour', 'Minute']:\n",
        "  plt.figure(figsize=(10,20))\n",
        "  sns.countplot(data=df, y= column) #linewidth=2, edgecolor=sns.color_palette(\"dark\", 3)) #palette=\"rainbow\"\n",
        "  plt.xticks(rotation=90, horizontalalignment='right', fontweight='light')\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "#Insights : \n",
        "\n",
        "#1. Most Accidents : Mornings - 7 to 10 ; Evenings - 3 to 7 \n",
        "#2. Every 5th Minute, Rise in accidents counts [Coincidental or convenience]"
      ],
      "metadata": {
        "id": "b_Xl9y1n3Py2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for column in df.select_dtypes(include=['object']).columns[:-1] :\n",
        "  sns.countplot(data=df, y= column, hue = 'Accident_severity') #linewidth=2, edgecolor=sns.color_palette(\"dark\", 3)) #palette=\"rainbow\"\n",
        "  plt.xticks(rotation=45, horizontalalignment='right', fontweight='light')\n",
        "  plt.show()\n",
        "\n",
        "for column in ['Hour', 'Minute']:\n",
        "  plt.figure(figsize=(10,20))\n",
        "  sns.countplot(data=df, y= column, hue = 'Accident_severity') #linewidth=2, edgecolor=sns.color_palette(\"dark\", 3)) #palette=\"rainbow\"\n",
        "  plt.xticks(rotation=90, horizontalalignment='right', fontweight='light')\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "#Insights : \n",
        "\n",
        "#1. More Fatal Injury accidents are on weekends [Sat & Sun] [May be due Drink & Drive?]\n",
        "#2. More Serious Injury & Fatal Injury accidents are with drivers fall under Age Band [18-30 & 31-50] \n",
        "#3. Very Less Serious Injury & No Fatal Injury, when Female Driver but that's not when Male driver [May be due Speed?]\n",
        "#4. Serious & Fatal Injuries are caused by Drivers with Education Levels : Elementary School, Junior High School, High School\n",
        "#5. More Serious & Fatal Injuries are caused by Drivers - who are employees.\n",
        "#6. Across all Driving Experience bands, Accidents. Majorly, Fatal Injuries are by Drivers with 2-10 Yrs Exp.\n",
        "#7. Fatal Injuries are caused by majorly Automobiles. More Serious Injuries are caused by Automobiles and Lorry/Heavy Vehicles.\n",
        "#8. More Serious & Fatal Injuries are caused by Private Owned Vehicles.\n",
        "#9. Majority of Accidents had happened in Areas : Other + Residential + Office and even Fatal Injuries.\n",
        "#10. Fatal Injuries happened in Undivided Two way or Two Way broken lanes.\n",
        "#11. Fatal Injuries happened in Tangent Roads with Flat Terrains.\n",
        "#12. Serious & Fatal Injuries happened in No Juntion or Y junction or Crossing.\n",
        "#13. Serious & Fatal Injuries happened while Moving backward or chnaging lanes.\n",
        "#14. Serious & Fatal Injuries happened during 3 PM To 10 PM and then 3-4AM in the morning.\n",
        "#15. Serious & Fatal Injuries happened when pedestrain movement in \"Not a Pedestrain\" zone."
      ],
      "metadata": {
        "id": "T-cuS8HJgrQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for column in df.select_dtypes(include=['object']).columns[:-1] :\n",
        "  # creating a facet grid with Target\n",
        "  grid = sns.FacetGrid(data=df, col='Accident_severity', height=4, aspect=1, sharey=False)\n",
        "  # mapping bar plot and the data on to the grid\n",
        "  grid.map(sns.countplot, column) #, palette=['blue', 'green', 'orange']\n",
        "  grid.set_xticklabels(rotation=90) #plt.xticks(rotation=45, horizontalalignment='right', fontweight='light')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "W9L92oRU97J5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = df.copy()"
      ],
      "metadata": {
        "id": "n1tTLfwMDhW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Data Pre-Prcoessing"
      ],
      "metadata": {
        "id": "S90CSoysC1A2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = data.copy()"
      ],
      "metadata": {
        "id": "9Tr1132W_0mD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1. Feature Value Transformations [Split/Extraction]"
      ],
      "metadata": {
        "id": "aqaJNC8iIwzf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Type_of_vehicle'] = df['Type_of_vehicle'].replace(['Long lorry', 'Lorry (41?100Q)', 'Lorry (11?40Q)', 'Pick up upto 10Q'], 'Lorry')\n",
        "\n",
        "df['Type_of_vehicle'] = df['Type_of_vehicle'].replace(['Bajaj', 'Motorcycle', 'Bicycle'], 'Bike')\n",
        "\n",
        "df['Type_of_vehicle'] = df['Type_of_vehicle'].replace(['Public (12 seats)', 'Public (13?45 seats)', 'Public (> 45 seats)'], 'Public')\n",
        "\n",
        "df['Type_of_vehicle'] = df['Type_of_vehicle'].replace(['Automobile', 'Taxi', 'Turbo', 'Special vehicle', 'Stationwagen'], 'Car')\n",
        "\n",
        "df['Type_of_vehicle'] = df['Type_of_vehicle'].replace(['Other', np.NaN], 'Other') \n",
        "\n",
        "df['Owner_of_vehicle'] = df['Owner_of_vehicle'].replace(['Other', np.NaN], 'Other') \n",
        "\n",
        "df['Area_accident_occured'] = df['Area_accident_occured'].replace(['Other', 'Unknown', np.NaN], 'Other') \n",
        "df['Area_accident_occured'] = df['Area_accident_occured'].replace(['Rural village areasOffice areas'], 'Rural village areas') \n",
        "\n",
        "df['Lanes_or_Medians'] = df['Lanes_or_Medians'].replace(['Other', 'unknown', np.NaN], 'Other') \n",
        "\n",
        "df['Types_of_Junction'] = df['Types_of_Junction'].replace(['Other', 'Unknown', np.NaN], 'Other') \n",
        "\n",
        "df['Road_surface_type'] = df['Road_surface_type'].replace(['Other', np.NaN], 'Other') \n",
        "\n",
        "df['Road_surface_conditions'] = df['Road_surface_conditions'].replace(['Flood over 3cm. deep', 'Wet or damp', 'Snow'], 'Wet') \n",
        "\n",
        "df['Light_conditions'] = df['Light_conditions'].replace(['Daylight', 'Darkness - lights lit'], 'Light') \n",
        "df['Light_conditions'] = df['Light_conditions'].replace(['Darkness - no lighting', 'Darkness - lights unlit'], 'Dark') \n",
        "\n",
        "df['Weather_conditions'] = df['Weather_conditions'].replace(['Cloudy', 'Raining', 'Raining and Windy','Cloudy', 'Windy', 'Snow', 'Fog or mist'], 'Abnormal') \n",
        "df['Weather_conditions'] = df['Weather_conditions'].replace(['Other', 'Unknown'], 'Normal') \n",
        "\n",
        "df['Type_of_collision'] = df['Type_of_collision'].replace(['Other', 'Unknown', np.NaN], 'Other') \n",
        "\n",
        "df['Vehicle_movement'] = df['Vehicle_movement'].replace(['Other', np.NaN], 'Other') \n",
        "\n",
        "df['Work_of_casuality'] = df['Work_of_casuality'].replace(['Other', 'Unknown', np.NaN], 'Other') \n",
        "\n",
        "df['Fitness_of_casuality'] = df['Fitness_of_casuality'].replace(['Other', np.NaN], 'Other') \n",
        "df['Fitness_of_casuality'] = df['Fitness_of_casuality'].replace(['NormalNormal'], 'Normal') \n",
        "\n",
        "df['Cause_of_accident'] = df['Cause_of_accident'].replace(['Other', 'Unknown'], 'Other') \n",
        "\n",
        "df['Pedestrian_movement'] = df['Pedestrian_movement'].replace([\"Crossing from driver's nearside\", 'Crossing from nearside - masked by parked or statioNot a Pedestrianry vehicle', 'Crossing from offside - masked by  parked or statioNot a Pedestrianry vehicle'], 'Crossing') \n",
        "df['Pedestrian_movement'] = df['Pedestrian_movement'].replace([\"In carriageway, statioNot a Pedestrianry - not crossing  (standing or playing)\", 'In carriageway, statioNot a Pedestrianry - not crossing  (standing or playing) - masked by parked or statioNot a Pedestrianry vehicle', 'Walking along in carriageway, back to traffic', 'Walking along in carriageway, facing traffic'], 'In carriageway') \n",
        "\n",
        "df['Cause_of_accident'] = df['Cause_of_accident'].replace(['Changing lane to the right', 'Changing lane to the left', 'Driving to the left'], 'Changing lanes') \n",
        "df['Cause_of_accident'] = df['Cause_of_accident'].replace(['Driving under the influence of drugs'], 'Drunk driving') \n",
        "df['Cause_of_accident'] = df['Cause_of_accident'].replace(['Driving at high speed'], 'Overspeed') \n"
      ],
      "metadata": {
        "id": "Q8Lh2cJhJHih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "min = list(range(5,56, 5))\n",
        "def convert_minutes(x: int):\n",
        "    for m in min:\n",
        "        if x % m == x and x > m-5:\n",
        "            return m\n",
        "        if x in [56,57,58,59]:\n",
        "            return 0\n",
        "        if x in min+[0]:\n",
        "            return x\n",
        "\n",
        "df['Minute'] = df['Minute'].apply(lambda x: convert_minutes(x))"
      ],
      "metadata": {
        "id": "uUUfAT0eiQwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.2. Missing Values Treatment"
      ],
      "metadata": {
        "id": "ObEvUvQTC4Wg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_drop = ['Defect_of_vehicle', 'Service_year_of_vehicle','Work_of_casuality','Fitness_of_casuality']\n",
        "\n",
        "df.drop(columns_to_drop, axis = 1, inplace = True) #20% + missing values"
      ],
      "metadata": {
        "id": "eredFUUxC9LC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.replace('Unknown', np.NaN, inplace = True)\n",
        "df.replace('unknown', np.NaN, inplace = True)\n",
        "# df.replace('na', np.NaN, inplace = True)"
      ],
      "metadata": {
        "id": "Jgu-Fv_QWoZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns_with_missing_values = missing_value_df[missing_value_df.percent_missing !=0.00].index[4:]\n",
        "\n",
        "for column in columns_with_missing_values:\n",
        "  #df[column].fillna(df[column].mode()[0], inplace=True) #Mode Imputation, as all categorical features.\n",
        "  df[column].fillna('Unknown', inplace=True) # Constant Imputation, as all categorical features."
      ],
      "metadata": {
        "id": "YhCS7pcPHlWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3. Encoding Techniques"
      ],
      "metadata": {
        "id": "KnubS3JMUZ1L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.preprocessing import LabelEncoder\n",
        "# encoder = LabelEncoder()\n",
        "\n",
        "# df = df.apply(encoder.fit_transform)"
      ],
      "metadata": {
        "id": "5fAVx4BiUiC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "\n",
        "df['Accident_severity'] = encoder.fit_transform(df['Accident_severity'])\n",
        "\n",
        "categorical_features = df.select_dtypes(include='object').columns\n",
        "\n",
        "for feature in categorical_features : \n",
        "  df = pd.get_dummies(df, prefix = ['Temp'+'_'+feature], columns = [feature], drop_first = False)"
      ],
      "metadata": {
        "id": "8oKqmGr-BkTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plt.figure(figsize = [25,15])\n",
        "# sns.heatmap(df.corr(), annot = True, mask = np.triu(np.ones_like(df.corr(), dtype=bool)))"
      ],
      "metadata": {
        "id": "95pL6yYEW2H0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.4. Imbalanced Data Treatment"
      ],
      "metadata": {
        "id": "A6Z8te0BUkim"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from imblearn.over_sampling import RandomOverSampler\n",
        "#sampler = RandomOverSampler()\n",
        "\n",
        "# from imblearn.over_sampling import SMOTE\n",
        "# sampler = SMOTE()\n",
        "\n",
        "\n",
        "# X = df.drop('Accident_severity', axis=1)\n",
        "# y = df['Accident_severity']\n",
        "\n",
        "# X,y = sampler.fit_resample(X,y)"
      ],
      "metadata": {
        "id": "cozm7JvXUnvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.5. Skewed Data Treatment"
      ],
      "metadata": {
        "id": "zbBhO1myVBRV"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bhMS4ZJAVEGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.6. Outlier Treatment"
      ],
      "metadata": {
        "id": "xjetqlHZVEmb"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JFa99ObNVJ4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.7. Feature Scaling"
      ],
      "metadata": {
        "id": "KgnJRAc3VKLS"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gfzYUj_sVOH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.8. Binning"
      ],
      "metadata": {
        "id": "Ib5ZnXt1VoBh"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G_krsJ8YVoZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.9. Grouping Operations"
      ],
      "metadata": {
        "id": "xJlWqwLJVt2D"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jvV55i0HVwek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.10. Dimensionality Reduction"
      ],
      "metadata": {
        "id": "hOZKYLFdVOiq"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qq4jC_KgVS4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.11. Multi-Colinearity Treatment"
      ],
      "metadata": {
        "id": "9CQHrAj6mk_T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "  \n",
        "# VIF dataframe\n",
        "vif_data = pd.DataFrame()\n",
        "vif_data[\"feature\"] = df.columns\n",
        "  \n",
        "# calculating VIF for each feature\n",
        "vif_data[\"VIF\"] = [variance_inflation_factor(df.values, i) for i in range(len(df.columns))]\n",
        "  \n",
        "print(vif_data) #VIF =1 -> No Correlation VIF = 1 to 5 -> Medium Correlation VIF > 5 -> Severe Correlation\n",
        "\n",
        "#Refer Article : https://www.statology.org/multicollinearity-regression/ to treat."
      ],
      "metadata": {
        "id": "3PRj011vmo3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vif_data[vif_data['VIF'] >= 5])"
      ],
      "metadata": {
        "id": "3A_vNSelWHn0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. ML Modelling"
      ],
      "metadata": {
        "id": "gkT3qSo-k9uV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1. Train Test Split"
      ],
      "metadata": {
        "id": "aq1xMbmslJAu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df.drop('Accident_severity', axis=1)\n",
        "y = df['Accident_severity']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1, stratify = y)\n",
        "\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
      ],
      "metadata": {
        "id": "YFgdztatlLtb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "sampler = SMOTE()\n",
        "\n",
        "X_train,y_train = sampler.fit_resample(X_train,y_train)"
      ],
      "metadata": {
        "id": "EdA6U9TeZ7rS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "counter = Counter(y_train)\n",
        "\n",
        "print(\"=============================\")\n",
        "\n",
        "for k,v in counter.items():\n",
        "    per = 100*v/len(y_train)\n",
        "    print(f\"Class= {k}, n={v} ({per:.2f}%)\")"
      ],
      "metadata": {
        "id": "021vp5pcoHK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2. Feature Selection"
      ],
      "metadata": {
        "id": "hFtlyHsalBtZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "from matplotlib import pyplot\n",
        "\n",
        "def get_features_scores(X_train, y_train):\n",
        "\tfs = SelectKBest(score_func=chi2, k='all')\n",
        "\tfs.fit(X_train, y_train)\n",
        "\treturn fs\n",
        "\n",
        "fs = get_features_scores(X_train, y_train)\n",
        "\n",
        "# for i in range(len(fs.scores_)):\n",
        "# \tprint('Feature %d: %f' % (i, fs.scores_[i]))\n",
        "# # plot the scores\n",
        "# pyplot.bar([i for i in range(len(fs.scores_))], fs.scores_)\n",
        "# pyplot.show()"
      ],
      "metadata": {
        "id": "qodV8AoelISr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = pd.Series(fs.scores_)"
      ],
      "metadata": {
        "id": "wWhFH1SH50t6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def select_features(X_train, y_train, X_test, k):\n",
        "\tfs = SelectKBest(score_func=chi2, k=k)\n",
        "\tfs.fit(X_train, y_train)\n",
        "\tX_train_fs = fs.transform(X_train)\n",
        "\tX_test_fs = fs.transform(X_test)\n",
        "\treturn X_train_fs, X_test_fs\n",
        "\n",
        "X_train_fs, X_test_fs = select_features(X_train, y_train, X_test, 10) #scores[scores > scores.mean()].shape[0]"
      ],
      "metadata": {
        "id": "4Omph3hp3TIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.3. Training the Model"
      ],
      "metadata": {
        "id": "HQeVV05slMQd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(random_state=1)\n",
        "model.fit(X_train_fs, y_train)"
      ],
      "metadata": {
        "id": "p6gd3ZzElP_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.4. Evaluating the Model"
      ],
      "metadata": {
        "id": "NAImHVMhlQQK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test_fs)\n",
        "\n",
        "print(f1_score(y_test, y_pred, average='weighted'))"
      ],
      "metadata": {
        "id": "NlewOMfHlWNU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(y_test, y_pred)"
      ],
      "metadata": {
        "id": "NniZNt3nsHta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "t-JbQ79vsXjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.5. AutoML"
      ],
      "metadata": {
        "id": "2WamimBZoA4Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install TPOT"
      ],
      "metadata": {
        "id": "ka-mJOxDsUCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "# from tpot import TPOTClassifier"
      ],
      "metadata": {
        "id": "yrpjjZsus2nE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # define model evaluation\n",
        "# cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=1, random_state=1)\n",
        "\n",
        "# #Custom Scoring function\n",
        "# #f1 = make_scorer(f1_score, average='weighted')\n",
        "\n",
        "# # define search\n",
        "# model = TPOTClassifier(generations=10, population_size=100, cv=cv, scoring= 'f1_weighted', verbosity=2, random_state=1, n_jobs=-1, early_stop = 50, periodic_checkpoint_folder=\"tpot_checkpoint.txt\", memory = 'auto') #, config_dict='TPOT light'\n",
        "# # perform the search\n",
        "# model.fit(X_train_fs, y_train)\n",
        "# # export the best model\n",
        "# model.export('tpot_best_model.py')"
      ],
      "metadata": {
        "id": "0J12xU0jwLZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# # copy it there\n",
        "# !cp /content/tpot_best_model.py /content/drive/MyDrive"
      ],
      "metadata": {
        "id": "IK8OyoeAFah9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.6. Re-Fit with best Model from TPOT"
      ],
      "metadata": {
        "id": "zc1ixAq1AvDP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# exported_pipeline = GradientBoostingClassifier(learning_rate=0.1, max_depth=10, max_features=0.4, min_samples_leaf=2, min_samples_split=5, n_estimators=100, subsample=0.45)\n",
        "# # Fix random state in exported estimator\n",
        "# if hasattr(exported_pipeline, 'random_state'):\n",
        "#     setattr(exported_pipeline, 'random_state', 1)\n",
        "\n",
        "# exported_pipeline.fit(X_train_fs, y_train)"
      ],
      "metadata": {
        "id": "Odi5KWCtA1tG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# y_pred = exported_pipeline.predict(X_test_fs)\n",
        "\n",
        "# print(f1_score(y_test, y_pred, average='weighted'))"
      ],
      "metadata": {
        "id": "uYNXMuwmBdMu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# confusion_matrix(y_test, y_pred)"
      ],
      "metadata": {
        "id": "ygyEXsXwBkEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "R2-Mrc34BnH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.7. Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "N5Z9QB8FC5iI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# p_test3 = {'learning_rate':[0.15,0.1,0.05,0.01,0.005,0.001], 'n_estimators':[100,250,500,750,1000]}\n",
        "\n",
        "# tuning = GridSearchCV(estimator = GradientBoostingClassifier(max_depth=10, max_features=0.4, min_samples_leaf=2, min_samples_split=5, subsample=0.45), \n",
        "#             param_grid = p_test3, scoring='f1_weighted', n_jobs=-1, cv=5)\n",
        "\n",
        "# tuning.fit(X_train_fs,y_train)\n",
        "\n",
        "# tuning.grid_scores_, tuning.best_params_, tuning.best_score_"
      ],
      "metadata": {
        "id": "UsVD8EWyC9Il"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.8. Save Model"
      ],
      "metadata": {
        "id": "xwKkJezo--B6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pipreqs -q"
      ],
      "metadata": {
        "id": "8_11p3qx_Atg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pipreqs ."
      ],
      "metadata": {
        "id": "o5ebIzQB_ZvJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install streamlit -q"
      ],
      "metadata": {
        "id": "l0FvLFixCUrI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !python --version"
      ],
      "metadata": {
        "id": "XBqz1gmyCcl1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "\n",
        "joblib.dump(model, \"model.joblib\")"
      ],
      "metadata": {
        "id": "vigVQpdtEYaH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}